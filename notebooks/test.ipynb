{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d82560a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "response = litellm.completion(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hi\"}],\n",
    "    num_retries=10,\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea341f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"To start solving the puzzle, I'll first need to move all the pieces closer to the container to prepare for assembling them into a cube.\\n\\nLet's move each piece to a position adjacent to the container, starting with object_id=8. Once they're close, we'll determine the rotations and arrangements needed for them to fit together perfectly.\\n\\nI need to observe the container closely, let's rotate the camera to get a side view, which might help with positioning and maneuvering pieces effectively.\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_nzXrIJVT64qpB5OpNlnQjgMg', function=Function(arguments='{\"angle\":90}', name='observe'), type='function', index=0)], reasoning=None)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "import os\n",
    "base_url = os.environ.get(\"OPENAI_BASE_URL\", \"https://openrouter.ai/api/v1\")\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key, base_url=base_url\n",
    ")\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"../logs/puzzle_assembly_quick_test_20251007_121114/images/step_0.png\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": '''3D CUBE STACKING PUZZLE\n",
    "\n",
    "You have 7 3D puzzle pieces and one container.\n",
    "\n",
    "TASK:\n",
    "Assemble all pieces into the container to form a solid 3×3×3 cube (27 unit cubes total).\n",
    "\n",
    "GOAL:\n",
    "- Fit every piece completely inside the container.\n",
    "- No gaps, overlaps, or floating pieces.\n",
    "- The final structure must be stable and form a perfect cube.\n",
    "\n",
    "ACTION RULE:\n",
    "- You can move or rotate one piece at a time.\n",
    "- Continue placing pieces until the cube is fully assembled.\n",
    "\n",
    "\n",
    "OBJECT MAPPING (object_id → properties):\n",
    "============================================================\n",
    "object_id=8, RGB=(201, 88, 0)\n",
    "object_id=7, RGB=(23, 115, 206)\n",
    "object_id=6, RGB=(0, 87, 43)\n",
    "object_id=5, RGB=(222, 197, 12)\n",
    "object_id=4, RGB=(0, 42, 113)\n",
    "object_id=3, RGB=(169, 27, 0)\n",
    "object_id=2, RGB=(153, 48, 97)\n",
    "============================================================\n",
    "Total movable objects: 7\n",
    "\n",
    "Now, what's your next action?'''\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{'type': 'function', 'function': {'name': 'move_object', 'description': 'Move an object to a specific 3D position in the workspace. The object will be teleported to the target position instantly. CONSTRAINTS: Position coordinates should be within the workspace bounds (typically -2.0 to 2.0 meters for x and y, 0.0 to 2.0 meters for z). Objects moved above ground (z > 0) will fall under gravity.', 'parameters': {'type': 'object', 'properties': {'object_id': {'type': 'integer', 'description': 'Unique object_id (integer) of the object to move. Get this from the observation state.'}, 'position': {'type': 'array', 'items': {'type': 'number'}, 'minItems': 3, 'maxItems': 3, 'description': 'Target position [x, y, z] in meters. Example: [0.5, 0.2, 0.1]. Ensure z >= 0 to keep objects above ground.'}}, 'required': ['object_id', 'position']}}}, {'type': 'function', 'function': {'name': 'rotate_object', 'description': \"Rotate an object around a specified axis by a given angle. The rotation is applied relative to the object's current orientation. CONSTRAINTS: Angle should typically be between -180 and 180 degrees. Common angles: 90° for quarter turn, 180° for half turn.\", 'parameters': {'type': 'object', 'properties': {'object_id': {'type': 'integer', 'description': 'Unique object_id (integer) of the object to rotate. Get this from the observation state.'}, 'axis': {'type': 'string', 'enum': ['x', 'y', 'z'], 'description': \"Rotation axis: 'x' for pitch, 'y' for yaw, 'z' for roll\"}, 'angle': {'type': 'number', 'description': 'Rotation angle in degrees (positive = counter-clockwise when viewing along the axis). Typical range: -180 to 180.'}}, 'required': ['object_id', 'axis', 'angle']}}}, {'type': 'function', 'function': {'name': 'observe', 'description': 'Change camera viewpoint to observe the scene from a different angle. The camera rotates around the center of the scene at a fixed distance. Use this to inspect objects from different perspectives. CONSTRAINTS: Angle wraps around at 360 degrees (0° = front view, 90° = right side, 180° = back, 270° = left side).', 'parameters': {'type': 'object', 'properties': {'angle': {'type': 'number', 'default': 0.0, 'description': 'Camera rotation angle in degrees around the scene center. 0° = front, 90° = right, 180° = back, 270° = left. Range: 0-360 (wraps around).'}}, 'required': ['angle']}}}, {'type': 'function', 'function': {'name': 'finish', 'description': 'Signal that you have completed the task successfully. ONLY call this when you believe all task objectives have been fully achieved. The system will evaluate your result after this call.', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}}, {'type': 'function', 'function': {'name': 'place_into_container', 'description': \"Place a puzzle piece into the container at a specified offset position relative to the container's center. This is a convenient alternative to move_object when placing pieces into the container. The piece will be positioned relative to the container's coordinate system. CONSTRAINTS: Offsets must be small to keep pieces inside the container. Use offset_z to stack pieces vertically.\", 'parameters': {'type': 'object', 'properties': {'object_id': {'type': 'integer', 'description': \"Unique object_id (integer) of the puzzle piece to place. Get this from the observation state. Do NOT use the container's object_id.\"}, 'offset_x': {'type': 'number', 'description': 'X offset from container center in meters. Positive = right, negative = left. RANGE: -0.1 to 0.1 (must keep piece inside container).', 'default': 0.0}, 'offset_y': {'type': 'number', 'description': 'Y offset from container center in meters. Positive = forward, negative = backward. RANGE: -0.1 to 0.1 (must keep piece inside container).', 'default': 0.0}, 'offset_z': {'type': 'number', 'description': 'Z offset from container bottom in meters. Use this for vertical stacking. RANGE: 0.0 to 0.15. Start from 0.0 for bottom layer, increase for higher layers.', 'default': 0.0}}, 'required': ['object_id']}}}],\n",
    "    tool_choice='auto',\n",
    ")\n",
    "print(chat_completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612bc391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {-1: (0.7882400155067444, 0.3450999855995178, 0.0, 1.0)}, 2: {-1: (0.09019999951124191, 0.45489999651908875, 0.8117600083351135, 1.0)}, 3: {-1: (0.0, 0.3411799967288971, 0.16863000392913818, 1.0)}, 4: {-1: (0.8705899715423584, 0.7725499868392944, 0.05098000168800354, 1.0)}, 5: {-1: (0.0, 0.16471000015735626, 0.4431400001049042, 1.0)}, 6: {-1: (0.6627500057220459, 0.10980000346899033, 0.0, 1.0)}, 7: {-1: (0.6000000238418579, 0.18824000656604767, 0.3843100070953369, 1.0)}, 8: {-1: (0.2117599993944168, 0.2117599993944168, 0.2117599993944168, 1.0)}}\n"
     ]
    }
   ],
   "source": [
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Connect to pybullet in DIRECT mode (no GUI)\n",
    "physicsClient = p.connect(p.DIRECT)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "\n",
    "# Load plane\n",
    "planeId = p.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# Find all urdf files under the specified directory\n",
    "urdf_root = r\"C:\\Users\\smj81\\Desktop\\VisualReasonBench\\src\\phyvpuzzle\\environment\\phobos_models\\3x3-stacking-puzzle\"\n",
    "urdf_files = []\n",
    "for root, dirs, files in os.walk(urdf_root):\n",
    "    for file in files:\n",
    "        if file.endswith(\".urdf\"):\n",
    "            urdf_files.append(os.path.join(root, file))\n",
    "\n",
    "# Optionally sort for consistent order\n",
    "urdf_files.sort()\n",
    "\n",
    "# Load all urdf files, spread them out in a grid for visibility\n",
    "loaded_ids = []\n",
    "num_per_row = int(np.ceil(np.sqrt(len(urdf_files))))\n",
    "spacing = 0.3\n",
    "for idx, urdf_path in enumerate(urdf_files):\n",
    "    row = idx // num_per_row\n",
    "    col = idx % num_per_row\n",
    "    x = (col - num_per_row / 2) * spacing\n",
    "    y = (row - num_per_row / 2) * spacing\n",
    "    z = 0.5\n",
    "    try:\n",
    "        obj_id = p.loadURDF(urdf_path, [x, y, z])\n",
    "        loaded_ids.append(obj_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {urdf_path}: {e}\")\n",
    "\n",
    "# 获取每个object的visual shape颜色\n",
    "obj_color_dict = {}\n",
    "for obj_id in loaded_ids:\n",
    "    visual_shapes = p.getVisualShapeData(obj_id)\n",
    "    # visual_shapes: list of tuples, each tuple: (objectUniqueId, linkIndex, visualGeometryType, dimensions, filename, meshScale, rgbaColor, ...)\n",
    "    # 可能有多个link, 这里只取第一个link的颜色\n",
    "    if visual_shapes:\n",
    "        # 取所有link的颜色\n",
    "        link_colors = {}\n",
    "        for vs in visual_shapes:\n",
    "            link_index = vs[1]\n",
    "            color = vs[7]  # rgbaColor\n",
    "            link_colors[link_index] = color\n",
    "        obj_color_dict[obj_id] = link_colors\n",
    "    else:\n",
    "        obj_color_dict[obj_id] = {}\n",
    "\n",
    "print(obj_color_dict)\n",
    "\n",
    "# Set camera parameters\n",
    "width, height = 512, 512\n",
    "view_matrix = p.computeViewMatrix(\n",
    "    cameraEyePosition=[1, 1, 1],\n",
    "    cameraTargetPosition=[0, 0, 0.5],\n",
    "    cameraUpVector=[0, 0, 1]\n",
    ")\n",
    "fov = 60\n",
    "aspect = width / height\n",
    "near = 0.1\n",
    "far = 3.1\n",
    "projection_matrix = p.computeProjectionMatrixFOV(\n",
    "    fov=fov,\n",
    "    aspect=aspect,\n",
    "    nearVal=near,\n",
    "    farVal=far\n",
    ")\n",
    "\n",
    "# Step simulation a few times to settle\n",
    "for _ in range(10):\n",
    "    p.stepSimulation()\n",
    "\n",
    "# Render the image\n",
    "img_arr = p.getCameraImage(\n",
    "    width=width,\n",
    "    height=height,\n",
    "    viewMatrix=view_matrix,\n",
    "    projectionMatrix=projection_matrix,\n",
    "    renderer=p.ER_BULLET_HARDWARE_OPENGL\n",
    ")\n",
    "\n",
    "rgb_array = np.reshape(img_arr[2], (height, width, 4))[:, :, :3]\n",
    "img = Image.fromarray(rgb_array.astype(np.uint8))\n",
    "\n",
    "# Show the image inline if in notebook, or save to file\n",
    "img.show()  # If running in a notebook, this will display the image\n",
    "\n",
    "# Disconnect\n",
    "p.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e862167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7f34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 看到的方块对应物理ID: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seg = img_arr[4]\n",
    "crop = seg[290:340, 230:290]\n",
    "id_counts = np.bincount(crop[crop >= 0].flatten())\n",
    "if len(id_counts) > 0:\n",
    "    target_id = np.argmax(id_counts)\n",
    "    print(\"AI 看到的方块对应物理ID:\", target_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5f3e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img.crop((190, 270, 270, 310))\n",
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42eee3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fac97f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2  3  4  5  6  8]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(img_arr[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2396f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,\n",
       "  -1,\n",
       "  5,\n",
       "  (0.005, 0.005, 0.005),\n",
       "  b'C:\\\\Users\\\\smj81\\\\Desktop\\\\VisualReasonBench\\\\src\\\\phyvpuzzle\\\\environment\\\\phobos_models\\\\3x3-stacking-puzzle\\\\obj_8\\\\urdf/../meshes/obj/bt_cube3x3_box.obj',\n",
       "  (0.29408, 0.66932, 0.07707),\n",
       "  (0.0, 0.0, 0.0, 1.0),\n",
       "  (0.2117599993944168, 0.2117599993944168, 0.2117599993944168, 1.0)),)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puzzle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
